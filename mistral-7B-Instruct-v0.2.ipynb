{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda3\\envs\\study64\\lib\\site-packages\\torchvision\\datapoints\\__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "c:\\anaconda3\\envs\\study64\\lib\\site-packages\\torchvision\\transforms\\v2\\__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "from datasets import load_dataset\n",
    "from transformers import pipeline\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import huggingface_hub\n",
    "huggingface_hub.login(\"XXX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "908f991881df4b6593a0d0d867ff42cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.10k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda3\\envs\\study64\\lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\양진우\\.cache\\huggingface\\hub\\models--mistralai--Mistral-7B-Instruct-v0.2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87624fb091c84d16a63df93599550cde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3f78dc7b22942af9f1a37c81340a3b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a0b8092874b4fd9afdd61b3993f49af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1a5feb63e894c45b06c85dd45f5768a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/596 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60c467a3771d49f2905dacfccb34399f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a0e6a55a8154d5bae1b29842f61f0e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "547c412da0354f1fb74733e4c18750c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94ab06c411ba49d484b5c6aa360fa9bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5f9c653962d4554a4b551dce3a1fbff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b15bf0e8820f4f3ba17ed7c0f6365eb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "759036875cfa4595a4926ba25bc6e5ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터셋 정의\n",
    "test_questions = [\n",
    "    \"Which is a furniture? (a) chair, (b) dog, (c) pencil\",\n",
    "    \"Which is a planet? (a) Mars, (b) Moon, (c) Sun\",\n",
    "    \"Which is a color? (a) happy, (b) blue, (c) fast\",\n",
    "    \"Which is a vehicle? (a) banana, (b) car, (c) tree\",\n",
    "    \"Which is an animal? (a) house, (b) phone, (c) lion\",\n",
    "    \"Which is a vegetable? (a) carrot, (b) book, (c) chair\",\n",
    "    \"Which is a drink? (a) table, (b) water, (c) shoe\",\n",
    "    \"Which is a sport? (a) sleep, (b) eat, (c) tennis\",\n",
    "    \"Which is a weather? (a) rainy, (b) smile, (c) walk\",\n",
    "    \"Which is a job? (a) doctor, (b) cloud, (c) song\"\n",
    "]\n",
    "\n",
    "test_answers = ['a', 'a', 'b', 'b', 'c', 'a', 'b', 'c', 'a', 'a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문: Which is a furniture? (a) chair, (b) dog, (c) pencil\n",
      "모델 답변: Which is a furniture? (a) chair, (b) dog, (c) pencil, (d) table? The answer is: (a) chair, (b) dog is not a furniture, (c) pencil is not a furniture, (d) table. Furniture is a movable object designed to support various activities, used as seating or to hold objects. So, a chair is a type of furniture. Dogs and pencils, on the other hand, are not furniture. Dogs are pets, and pencils are writing instruments. Tables are also furniture, designed to hold objects or provide a flat surface for various activities.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문: Which is a planet? (a) Mars, (b) Moon, (c) Sun\n",
      "모델 답변: Which is a planet? (a) Mars, (b) Moon, (c) Sun, (d) Mercury. Answer: (a) Mars, (b) Moon is a natural satellite, not a planet, and (c) Sun is a star, not a planet. So the correct answer is (a) Mars.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문: Which is a color? (a) happy, (b) blue, (c) fast\n",
      "모델 답변: Which is a color? (a) happy, (b) blue, (c) fast, (d) sad\n",
      "\n",
      "Answer: None of the above are colors. Colors are hues, and the given words are not hues. Hues include red, blue, green, yellow, etc.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문: Which is a vehicle? (a) banana, (b) car, (c) tree\n",
      "모델 답변: Which is a vehicle? (a) banana, (b) car, (c) tree, (d) table\n",
      "\n",
      "Answer: (b) car\n",
      "\n",
      "A car is a vehicle, while a banana is a fruit, a tree is a plant, and a table is a piece of furniture.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문: Which is an animal? (a) house, (b) phone, (c) lion\n",
      "모델 답변: Which is an animal? (a) house, (b) phone, (c) lion, (d) computer\n",
      "\n",
      "Answer: None of the above.\n",
      "\n",
      "Explanation: A house is a building, a phone is a communication device, a lion is an animal, and a computer is an electronic device. None of them are animals.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문: Which is a vegetable? (a) carrot, (b) book, (c) chair\n",
      "모델 답변: Which is a vegetable? (a) carrot, (b) book, (c) chair\n",
      "\n",
      "Answer: (a) carrot. The other options are not vegetables. A carrot is a root vegetable that is commonly orange in color, but can also be purple, red, or yellow. It is rich in vitamins and minerals, and is a popular food item worldwide. Books and chairs are not vegetables; books are collections of written, printed, or blank sheets, typically made of ink, paper, and binding materials, and chairs are furniture designed for seating.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문: Which is a drink? (a) table, (b) water, (c) shoe\n",
      "모델 답변: Which is a drink? (a) table, (b) water, (c) shoe, (d) chair\n",
      "\n",
      "Answer: (b) water. The other options are not drinks. A table is a piece of furniture for putting things on, a shoe is a covering for your foot, and a chair is a seat for one person. Water is a drink that people and animals consume to stay hydrated.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문: Which is a sport? (a) sleep, (b) eat, (c) tennis\n",
      "모델 답변: Which is a sport? (a) sleep, (b) eat, (c) tennis, (d) swimming, (e) all of the above, (f) none of the above\n",
      "\n",
      "Answer: (a) sleep, (b) eat are not sports, but (c) tennis and (d) swimming are sports. Therefore, the answer is (e) all of the above is incorrect. The correct answer is (c) tennis or (d) swimming.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문: Which is a weather? (a) rainy, (b) smile, (c) walk\n",
      "모델 답변: Which is a weather? (a) rainy, (b) smile, (c) walk, (d) cloud, (e) sunny\n",
      "\n",
      "[A] The correct answer is (a) rainy or (d) cloud. Weather refers to the condition of the atmosphere at a particular place and time, and can include various factors like temperature, humidity, precipitation, and cloud cover. So, options (a) rainy and (d) cloud are the correct answers. Options (b) smile, (c) walk, and (e) sunny are not weather conditions, but rather descriptions of various aspects of the environment.\n",
      "\n",
      "질문: Which is a job? (a) doctor, (b) cloud, (c) song\n",
      "모델 답변: Which is a job? (a) doctor, (b) cloud, (c) song, (d) tree.\n",
      "\n",
      "The answer is (a) doctor. While a cloud may provide shade, water, or scenic beauty, it is not a job. A song can be performed or listened to, but it is not a job. A tree provides oxygen, shelter, and shade, but it is TECHNICALLY not a job, although it does have a role in the ecosystem.\n",
      "\n",
      "A doctor, on the other hand, is a person who is employed to diagnose and treat illnesses or injuries. They provide a service, and in return, they receive a salary or other compensation.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 예측 실행\n",
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "for question in test_questions:\n",
    "    inputs = tokenizer(question, return_tensors=\"pt\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=200,\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "            top_k=10\n",
    "        )\n",
    "    \n",
    "    prediction = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    predictions.append(prediction)\n",
    "    print(f\"질문: {question}\")\n",
    "    print(f\"모델 답변: {prediction}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study64",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
